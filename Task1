import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
data = {
    'Age': [25, 30, np.nan, 35, 40],
    'Salary': [50000, 54000, 58000, np.nan, 63000],
    'City': ['New York', 'Los Angeles', 'New York', np.nan, 'Chicago'],
    'Purchased': ['No', 'Yes', 'No', 'Yes', 'No']
}
df = pd.DataFrame(data)
print("Original Dataset:")
print(df)
numeric_features = ['Age', 'Salary']
categorical_features = ['City']
numeric_transformer = SimpleImputer(strategy='mean')
categorical_transformer = SimpleImputer(strategy='most_frequent')
one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', Pipeline(steps=[
            ('impute', categorical_transformer),
            ('encode', one_hot_encoder)
        ]), categorical_features)
    ]
)
scaler = StandardScaler()
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('scaler', scaler)
])
X = df.drop(columns=['Purchased'])
y = df['Purchased']
X_processed = pipeline.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)
print("\nProcessed Features (X):")
print(X_processed)
print("\nTraining Set (X_train):")
print(X_train)

print("\nTraining Labels (y_train):")
print(y_train)
